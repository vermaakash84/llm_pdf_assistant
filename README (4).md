## ğŸ“š LLM PDF Research Assistant

**Goal:** Ask questions from large collections of PDF documents and get AI-generated responses using a Retrieval-Augmented Generation (RAG) approach.

---

### ğŸ”— Live Demo

[ğŸ‘‰ Try the App on Streamlit Cloud](https://your-app-link.streamlit.app)

---

### ğŸ“ Project Structure

```
llm_pdf_assistant/
â”œâ”€â”€ app.py                # Streamlit UI with batch toggle support
â”œâ”€â”€ requirements.txt      # Required packages
â”œâ”€â”€ db_batch_1/           # Vector store for batch 1 (auto-generated by Chroma)
â”œâ”€â”€ db_batch_2/           # Vector store for batch 2
â”œâ”€â”€ ...                   # More batches can be added
```

---

### âš™ï¸ Tools & Libraries

- **LangChain** (chains, document loaders, retrievers)
- **Hugging Face Transformers** (LLM backend: FLAN-T5)
- **ChromaDB** (local vector database)
- **PyMuPDF** (for PDF parsing)
- **Streamlit** (for UI deployment)

---

### ğŸ¤– How It Works

1. PDFs are split into chunks (1000 tokens with 200 overlap).
2. Each chunk is converted into embeddings using `all-MiniLM-L6-v2`.
3. Chunks are stored in ChromaDB.
4. User query is embedded and matched with top-k relevant chunks.
5. Retrieved text is passed to a Hugging Face LLM (FLAN-T5) for answer generation.

---

### ğŸ§ª Use Cases

- Legal Document Search (LegalTech)
- Policy and Governance Research
- Academic Q&A (EdTech)
- Consulting Knowledge Assistant

---

### ğŸ–¥ï¸ Run Locally

```bash
# 1. Clone repo
https://github.com/your-username/llm-pdf-assistant.git
cd llm-pdf-assistant

# 2. Install dependencies
pip install -r requirements.txt

# 3. Run app
streamlit run app.py
```

---

### ğŸ” License

This project is licensed under the [MIT License](LICENSE).

Feel free to modify and use this project for your own legal, research, or consulting tools.

---

### âœ¨ Author

**Akash Verma**\
[GitHub](https://github.com/vermaakash84) | [LinkedIn](https://linkedin.com/in/vermaakash84)

---

### ğŸ“Œ Future Improvements

- PDF upload from UI
- Multiple model toggle (FLAN, Mistral, OpenAI)
- Chat history with context window
- Token usage stats

